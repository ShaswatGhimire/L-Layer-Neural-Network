{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4aa8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import random \n",
    "import matplotlib.pyplot as plt \n",
    "import copy\n",
    "import scipy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd37508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OVERVIEW: \n",
    "We are going to implement a N-layer deep neural network ... so ... the input at first will be how many layers and the \n",
    "number of nodes in each layer... \n",
    "\n",
    "using that we will randomly initialize our parameter...  compete forward propagation using ReLU activation for every layer\n",
    "except last where we will use sigmoid activation \n",
    "than we will calculate cost ...  and update our parameters calculating the derivatives using bacward propagation\n",
    "\n",
    "combining all these above we then will build our model to train and predict \n",
    "\"\"\"\n",
    "\n",
    "#data reading and pre processing and assigning initial values \n",
    "\n",
    "#setting the path for the folder to read ... \n",
    "path1 = 'F:\\code files\\machine learning\\dogs vs cats classification\\dataset'\n",
    "\n",
    "#setting important values of image\n",
    "height = 64\n",
    "width = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa7f517d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_location(directory):\n",
    "    biglist = []\n",
    "    for folder in os.listdir(directory):\n",
    "        for file in os.listdir(os.path.join(directory,folder)):\n",
    "            location = os.path.join(directory,folder,file)\n",
    "            biglist.append([location,folder])\n",
    "    return biglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68b8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    #print(path)\n",
    "    #print(\"we are not in except also\")\n",
    "    image = np.array(Image.open(path))\n",
    "    image = np.resize(image, (height,width,3))\n",
    "    image = image.astype('float32')\n",
    "    image /= 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e537e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\lib\\site-packages\\PIL\\TiffImagePlugin.py:793: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training images loading done\n",
      "testing images loading done\n"
     ]
    }
   ],
   "source": [
    "#loading dataset of training images \n",
    "X_train_list = []\n",
    "Y_train_list = []\n",
    "directory = os.path.join(path1, 'Train')\n",
    "biglist = load_location(directory)\n",
    "for i in range(len(biglist)):\n",
    "    item = random.choice(biglist)\n",
    "    image_array = load_dataset(item[0])\n",
    "    X_train_list.append(image_array)\n",
    "    if item[1] == 'Dog':\n",
    "        Y_train_list.append(1)\n",
    "    else:\n",
    "        Y_train_list.append(0)\n",
    "    biglist.remove(item)\n",
    "print(\"training images loading done\")\n",
    "\n",
    "#loading dataset of testing images\n",
    "X_test_list = []\n",
    "Y_test_list = []\n",
    "directory = os.path.join(path1, 'Test')\n",
    "biglist = load_location(directory)\n",
    "for i in range(len(biglist)):\n",
    "    item = random.choice(biglist)\n",
    "    image_array = load_dataset(item[0])\n",
    "    X_test_list.append(image_array)\n",
    "    if item[1] == 'Dog':\n",
    "        Y_test_list.append(1)\n",
    "    else:\n",
    "        Y_test_list.append(0)\n",
    "    biglist.remove(item)\n",
    "print(\"testing images loading done\")\n",
    "\n",
    "#finding number of training and testing examples\n",
    "m_train = len(Y_train_list)\n",
    "m_test = len(Y_test_list)\n",
    "\n",
    "#converting our list data to numpy array and then flattening X value to (height*width*3 , 1) shape\n",
    "X_train = np.asarray(X_train_list).reshape(m_train, -1).T\n",
    "X_test = np.asarray(X_test_list).reshape(m_test, -1).T\n",
    "Y_train = np.asarray(Y_train_list).reshape(m_train,1).T\n",
    "Y_test = np.asarray(Y_test_list).reshape(m_test,1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7880876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model begins \n",
    "#first some helper functions \n",
    "\n",
    "#initializes random weights and zeros to w and b of all layer of our network\n",
    "def initialize_parameters(dims):\n",
    "    parameters = {}\n",
    "    L = len(dims)\n",
    "    for l in range(1,L):\n",
    "        parameters['W'+str(l)] = np.random.randn(dims[l],dims[l-1])*0.01\n",
    "        parameters['b'+str(l)] = np.zeros((dims[l],1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a18baab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f9359c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    s = np.maximum(0,z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15d7d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(z):\n",
    "    s = sigmoid(z) * (1-sigmoid(z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca6a7c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(z):\n",
    "    s = np.where(z>0, 1, 0)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "639a1a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    A = X\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    #a accumulator to hold information\n",
    "    caches = []\n",
    "    \n",
    "    for l in range(1,L):\n",
    "        cache = {}\n",
    "        A_old = A\n",
    "        W = parameters['W'+str(l)] \n",
    "        b = parameters['b'+str(l)]\n",
    "        #print(f\"W{l} {W.shape}  X  {A_old.shape} relu \")\n",
    "        Z = np.dot(W, A_old)+b\n",
    "        A = relu(Z)\n",
    "        cache['Z'] = Z\n",
    "        cache['A_prev'] = A_old\n",
    "        cache['W'] = W \n",
    "        cache['A'] = A\n",
    "        caches.append(cache)\n",
    "    \n",
    "    cache = {}\n",
    "    A_old = A\n",
    "    W = parameters['W'+str(L)]\n",
    "    b = parameters['b'+str(L)]\n",
    "    #print(f\"W{L} {W.shape}  X  {A_old.shape} sigmoid\")\n",
    "    Z = np.dot(W, A_old)+b\n",
    "    A = sigmoid(Z)\n",
    "    #print(A.shape)\n",
    "    cache['Z']  = Z\n",
    "    cache['A_prev'] = A_old\n",
    "    cache['W']  = W\n",
    "    cache['b'] = b\n",
    "    cache['A'] = A\n",
    "    caches.append(cache)\n",
    "         \n",
    "    return A,caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15fc7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(AL , Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = np.add(np.dot(Y, np.log(AL).T), np.dot((1-Y), np.log(1-AL).T))/(-m)\n",
    "    J = np.squeeze(cost)\n",
    "    #print(J.shape)\n",
    "    return J\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d66338ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_back(cache, dA,  activation):\n",
    "    Z = cache['Z']\n",
    "    A_prev = cache['A_prev']\n",
    "    W = cache['W']\n",
    "    \n",
    "    #print(Z.shape ,'Z shape')\n",
    "    #print(dA.shape , 'da shape')\n",
    "    #print(A_prev.shape , ' A prev shape')\n",
    "    \n",
    "    \n",
    "    m = A_prev.shape[1]\n",
    "    if activation == 'relu':\n",
    "        dZ = dA * relu_backward(Z)\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = dA * sigmoid_backward(Z)\n",
    "        #print(A_prev.shape , 'A_prev shape')\n",
    "    dW = np.dot(dZ, A_prev.T)/m\n",
    "    #print(dW.shape, 'dw shape')\n",
    "    #print(W.shape, 'W shape')\n",
    "    #print(activation)\n",
    "    db = np.sum(dZ, axis = 1, keepdims = True)/m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1392bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(caches, Y, Al ):\n",
    "    #print(len(caches))\n",
    "    L = len(caches)\n",
    "    m = Al.shape[1]\n",
    "    dAl = - (np.divide(Y,Al) - np.divide((1-Y),(1-Al)))\n",
    "    grads = {}\n",
    "    \n",
    "    cache = caches[L-1]\n",
    "    dA_prev , dW, db = linear_back(cache, dAl,  'sigmoid')\n",
    "    \n",
    "    grads['dA'+str(L-1)] = dA_prev\n",
    "    grads['dW'+str(L)] = dW\n",
    "    grads['db'+str(L)] = db\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        cache = caches[l]\n",
    "        dA_prev , dW, db = linear_back(cache,dA_prev, 'relu')\n",
    "        grads['dA'+str(l)] = dA_prev\n",
    "        grads['dW'+str(l+1)] = dW\n",
    "        grads['db'+str(l+1)] = db\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5c12014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    parameters = parameters.copy()\n",
    "    L = len(parameters)//2\n",
    "    for l in range(L): \n",
    "        parameters['W'+str(l+1)] = parameters['W'+str(l+1)] - learning_rate * grads['dW'+str(l+1)]\n",
    "        parameters['b'+str(l+1)] = parameters['b'+str(l+1)] - learning_rate * grads['db'+str(l+1)]\n",
    "        \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cc98719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, parameters):\n",
    "    Al, caches = forward_propagation(X, parameters)\n",
    "    predictions = np.where(Al>0.5, 1, 0)\n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d3010d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test , layer_dimension, learning_rate = 0.001, num_of_iterations = 1000):\n",
    "    parameters = initialize_parameters(layer_dimension)\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_of_iterations):\n",
    "        Al, caches = forward_propagation(X_train, parameters)\n",
    "        J = cost(Al, Y_train)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"the cost after {i}th iteration is {J}\")\n",
    "        costs.append(J)\n",
    "        grads = back_propagation(caches , Y_train , Al)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "    train_predictions = predict(X_train, parameters)\n",
    "    test_predictions = predict(X_test, parameters)\n",
    "    \n",
    "    train_accuracy = 100 - np.mean(np.abs(train_predictions - Y_train))*100\n",
    "    test_accuray = 100 - np.mean(np.abs(test_predictions - Y_test))*100\n",
    "    \n",
    "    print(f\"train accuracy is {train_accuracy}\")\n",
    "    print(f\"test accuray is {test_accuray}\")\n",
    "    \n",
    "    return parameters, costs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79f04f5b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cost after 0th iteration is 0.6931469801506738\n",
      "the cost after 100th iteration is 0.6931469790648933\n",
      "the cost after 200th iteration is 0.693146977942565\n",
      "the cost after 300th iteration is 0.6931469767629259\n",
      "the cost after 400th iteration is 0.6931469755733445\n",
      "the cost after 500th iteration is 0.6931469743861299\n",
      "the cost after 600th iteration is 0.6931469731922535\n",
      "the cost after 700th iteration is 0.6931469719817984\n",
      "the cost after 800th iteration is 0.693146970750666\n",
      "the cost after 900th iteration is 0.6931469695065473\n",
      "train accuracy is 50.002427302296226\n",
      "test accuray is 50.0\n"
     ]
    }
   ],
   "source": [
    "features = height * width * 3\n",
    "layer_dimension = [features, 5,4,1]\n",
    "parameters, costs = model(X_train, Y_train, X_test, Y_test , layer_dimension, learning_rate = 0.001, num_of_iterations = 1000)\n",
    "#print(parameters, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfe7c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045e6d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
